export const step8Data = {
  "LLM-as-a-judge": {
    title: "LLM-as-a-Judge",
    description: "Learn the powerful technique of using a capable LLM to evaluate the quality of another model's output based on a set of criteria, automating parts of the evaluation process.",
    learningPoints: []
  },
  "Multi-turn evals": {
    title: "Multi-turn Evaluations",
    description: "Understand how to evaluate the performance of conversational AI over multiple turns, assessing aspects like coherence, context retention, and user goal completion.",
    learningPoints: []
  },
  "AI Agent Evaluation": {
    title: "AI Agent Evaluation",
    description: "Explore frameworks and metrics for evaluating AI agents, focusing not just on the final output but also on the correctness of their reasoning and tool use.",
    learningPoints: []
  },
  "Component-level evals": {
    title: "Component-level Evaluations",
    description: "Learn to isolate and evaluate individual components of a complex AI system (like the retriever in a RAG pipeline) to identify and address bottlenecks.",
    learningPoints: []
  },
  "Observability platforms": {
    title: "Observability Platforms",
    description: "Discover tools like LangSmith, Arize, or Weights & Biases that provide tracing, logging, and monitoring capabilities specifically designed for LLM applications.",
    learningPoints: []
  },
  "AI Agent instrumentation": {
    title: "AI Agent Instrumentation",
    description: "Learn how to embed logging and tracing within your agents to gain visibility into their internal state, tool calls, and decision-making processes.",
    learningPoints: []
  }
};
